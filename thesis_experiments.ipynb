{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/medha-hegde/master_thesis/blob/main/thesis_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone Repo\n",
        "import os\n",
        "\n",
        "if not os.path.exists(\"master_thesis\"):\n",
        "  !git clone https://github.com/medha-hegde/master_thesis.git"
      ],
      "metadata": {
        "id": "UDKVq0B_d4va",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Dependencies and Restart Runtime\n",
        "%cd /content/\n",
        "!pip install -r master_thesis/requirements.txt -qq\n",
        "\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lBfQzxhueNhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mu9D30lSwt-U",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run Preliminary Experiment\n",
        "\n",
        "%cd '/content/master_thesis/preliminary experiments'\n",
        "# !cp '/content/master_thesis/preliminary experiments/prelim_exp.py' .\n",
        "# !cp '/content/master_thesis/preliminary experiments/prelim_helpers.py' .\n",
        "\n",
        "exp_name = \"experiment 1\" #@param [\"experiment 1\", \"experiment 2\", \"experiment 3\", \"experiment 4\"] {allow-input: true}\n",
        "\n",
        "from prelim_exp import run_prelim_exp\n",
        "run_prelim_exp(exp_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Character Probe Experiment\n",
        "model_card = \"openai/clip-vit-large-patch14\" #@param [\"openai/clip-vit-base-patch32\", \"openai/clip-vit-large-patch14\", \"t5-base\", \"t5-large\"] {allow-input: true}\n",
        "# device = \"gpu\"\n",
        "\n",
        "%cd '/content/master_thesis/character-probe'\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Replace model name in params file\n",
        "# Read in the file\n",
        "with open('params.py', 'r') as file :\n",
        "  filedata = file.read()\n",
        "\n",
        "# Replace the target string\n",
        "\n",
        "for model_name in [\"openai/clip-vit-base-patch32\", \"openai/clip-vit-large-patch16\", \"t5-base\", \"t5-large\"]:\n",
        "  if model_name in filedata:\n",
        "      filedata = filedata.replace( model_name,model_card)\n",
        "\n",
        "# Write the file out again\n",
        "with open('params.py', 'w') as file:\n",
        "  file.write(filedata)\n",
        "\n",
        "!python3 train.py "
      ],
      "metadata": {
        "id": "orOoSGUxbzgC",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Experiments"
      ],
      "metadata": {
        "id": "ft_ccna5C0RD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_encoder_name = \"openai/clip-vit-large-patch14\" #@param [\"openai/clip-vit-base-patch32\", \"openai/clip-vit-large-patch14\", \"t5-small\", \"t5-base\",\"google/byt5-small\",\"google/byt5-base\"] {allow-input: true}\n",
        "epochs = 150 #@param {type:\"number\"}\n",
        "combine_with_text_encoder = \"None\" #@param [\"None\",\"openai/clip-vit-base-patch32\", \"openai/clip-vit-large-patch14\", \"t5-small\", \"t5-base\",\"google/byt5-small\",\"google/byt5-base\"] {allow-input: true}\n",
        "\n",
        "# W&B Configs\n",
        "\n",
        "import wandb\n",
        "config = {\n",
        "  \"pretrained_model_name_or_path\" : text_encoder_name,\n",
        "   \"pretrained_model_name_or_path_2\" : combine_with_text_encoder,\n",
        "    \"textmodel_maxtokens\" : 77,\n",
        "    \"text_prompt\" : \"a black and white image of the word\",\n",
        "    \"img_size\" : 64,\n",
        "    \"sample_batch_size\" : 64,\n",
        "    \"dummy_run\": False,\n",
        "    \"batch_size\": 128,\n",
        "    \"model_name\" :\"transformer\",\n",
        "    \"model_save_path\" : \"/content/\",\n",
        "    \"checkpoint\" : None,\n",
        "    \"lr\" : 10e-4,\n",
        "    \"epochs\" : epochs,\n",
        "    \"device\" : \"cuda\"\n",
        "\n",
        "}\n",
        "config[\"run_name\"] = config[\"pretrained_model_name_or_path\"].replace(\"/\",\"_\")\n",
        "\n",
        "\n",
        "%cd '/content/master_thesis'\n",
        "\n",
        "from main_experiments.create_imgs import create_imgs\n",
        "from main_experiments.text_model import load_text_model\n",
        "from main_experiments.create_torch_dataset import create_torch_dataset\n",
        "from main_experiments.unet_setup import UNet_SD, marginal_prob_std_fn, get_n_params\n",
        "import torch\n",
        "\n",
        "# Create Training Image-Text Dataset\n",
        "create_imgs(config)\n",
        "\n",
        "# Load Text Model + tokenizer\n",
        "tokenizer, text_encoder = load_text_model(config[\"pretrained_model_name_or_path\"])\n",
        "config[\"text_emb_length\"]  = list(text_encoder.named_parameters())[0][1].shape[1]\n",
        "config[\"text_emb_length_2\"]  = 0\n",
        "\n",
        "if combine_with_text_encoder != \"None\":\n",
        "  tokenizer_2, text_encoder_2 = load_text_model(config[\"pretrained_model_name_or_path_2\"])\n",
        "  config[\"text_emb_length_2\"]  = list(text_encoder_2.named_parameters())[0][1].shape[1]\n",
        "\n",
        "\n",
        "# Create torch dataset\n",
        "if combine_with_text_encoder == \"None\":\n",
        "  train_dataloader = create_torch_dataset(config, tokenizer)\n",
        "else:\n",
        "  train_dataloader = create_torch_dataset(config, tokenizer, tokenizer_2)\n",
        "\n",
        "\n",
        "\n",
        "# Load U-Net model\n",
        "device = \"cuda\"\n",
        "context_dim = config[\"text_emb_length\"] + config[\"text_emb_length_2\"] \n",
        "\n",
        "score_model = torch.nn.DataParallel(UNet_SD(marginal_prob_std=marginal_prob_std_fn,context_dim=context_dim))\n",
        "score_model = score_model.to(device)\n",
        "config[\"no_of_params\"] = get_n_params(score_model)\n",
        "\n",
        "# Run Training \n",
        "\n",
        "if config[\"checkpoint\"] is not None:\n",
        "  checkpoint = torch.load(config[\"checkpoint\"], map_location=device)\n",
        "else:\n",
        "  checkpoint = None\n",
        "\n",
        "\n",
        "wandb.init(project=\"text-encoder-experiments_testing\",name = config[\"run_name\"])\n",
        "wandb.config.update(config)\n",
        "\n",
        "from main_experiments.train import train_diffusion_model\n",
        "  \n",
        "train_diffusion_model(config,\n",
        "                      train_dataloader,\n",
        "                      score_model,\n",
        "                      tokenizer,\n",
        "                      text_encoder,\n",
        "                      tokenizer_2=tokenizer_2 if combine_with_text_encoder != \"None\" else None,\n",
        "                      text_encoder_2=text_encoder_2 if combine_with_text_encoder != \"None\" else None,\n",
        "                      n_epochs =  config[\"epochs\"],\n",
        "                      lr=config[\"lr\"],\n",
        "                      model_name=config[\"model_name\"],\n",
        "                      checkpoint = checkpoint,\n",
        "                      model_save_path=config[\"model_save_path\"],\n",
        "                      dummy_run=config[\"dummy_run\"])\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dTd3P23FKJqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run OCR\n",
        "model_name = \"CLIP_small\" #@param \n",
        "model_saved_path = \"/content/ckpt_transformer_clip_t5.pt\" #@param \n",
        "text_encoder_name = \"openai/clip-vit-base-patch32\" #@param [\"openai/clip-vit-base-patch32\", \"openai/clip-vit-large-patch14\", \"t5-small\", \"t5-base\",\"google/byt5-small\",\"google/byt5-base\"] {allow-input: true}\n",
        "combine_with_text_encoder = \"None\" #@param [\"None\",\"openai/clip-vit-base-patch32\", \"openai/clip-vit-large-patch14\", \"t5-small\", \"t5-base\",\"google/byt5-small\",\"google/byt5-base\"] {allow-input: true}\n",
        "\n",
        "\n",
        "ocr_configs = {\"model_name\" : model_name,\n",
        "              \"model_card\" : text_encoder_name,\n",
        "               \"pretrained_model_name_or_path_2\" : combine_with_text_encoder,\n",
        "                \"model_saved_path\" : model_saved_path,\n",
        "              \"textmodel_maxtokens\" : 77,\n",
        "              \"device\" : \"cuda\"}\n",
        "\n",
        "%cd '/content/master_thesis'\n",
        "from main_experiments.ocr import run_ocr\n",
        "\n",
        "run_ocr(ocr_configs)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fcbqzsBRWfba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot OCR Results\n",
        "model_1_name =  'CLIP' #@param \n",
        "model_2_name = 'T5' #@param \n",
        "model_3_name = 'ByT5' #@param \n",
        "\n",
        "model_1_saved_path = \"small_ocr_resultsCLIP.json\" #@param \n",
        "model_2_saved_path = \"small_ocr_resultsT5.json\" #@param \n",
        "model_3_saved_path = \"small_ocr_resultsByT5.json\" #@param \n",
        "\n",
        "ocr_plot_configs = {\"model_names\" : [model_1_name,model_2_name,model_3_name],\n",
        "                    \"model_paths\" : [model_1_saved_path,model_2_saved_path,model_3_saved_path]\n",
        "}\n",
        "\n",
        "%cd '/content/master_thesis'\n",
        "from main_experiments.ocr import ocr_plot\n",
        "\n",
        "ocr_plot(ocr_plot_configs)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sONXnpxtp8Z2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}